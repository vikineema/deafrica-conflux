{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40945bc4-a1e3-4894-aecf-490ba221ce35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# These are the default AWS configurations for the Analysis Sandbox.\n",
    "# that are set in the environmnet variables. \n",
    "aws_default_config = {\n",
    "    #'AWS_NO_SIGN_REQUEST': 'YES', \n",
    "    'AWS_SECRET_ACCESS_KEY': 'fake',\n",
    "    'AWS_ACCESS_KEY_ID': 'fake',\n",
    "}\n",
    "\n",
    "# To access public bucket, need to remove the AWS credentials in \n",
    "# the environment variables or the following error will occur.\n",
    "# PermissionError: The AWS Access Key Id you provided does not exist in our records.\n",
    "\n",
    "for key in aws_default_config.keys():\n",
    "    if key in os.environ:\n",
    "        del os.environ[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bf3dbc-a461-4639-9770-b622a698846d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import os\n",
    "from importlib import import_module\n",
    "\n",
    "import click\n",
    "import datacube\n",
    "import fsspec\n",
    "from odc import dscache\n",
    "from odc.aws import s3_download\n",
    "from rasterio.errors import RasterioIOError\n",
    "\n",
    "from deafrica_conflux.cli.logs import logging_setup\n",
    "from deafrica_conflux.drill import drill\n",
    "from deafrica_conflux.io import (\n",
    "    check_dir_exists,\n",
    "    check_file_exists,\n",
    "    check_if_s3_uri,\n",
    "    table_exists,\n",
    "    write_table_to_parquet,\n",
    ")\n",
    "from deafrica_conflux.plugins.utils import run_plugin, validate_plugin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d58273a-5eea-48bc-8b46-a2edade04e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = 1\n",
    "# File path to the cache file database.\n",
    "cachedb_file_path = \"s3://deafrica-waterbodies-dev/waterbodies/v0.0.2/senegal_basin/conflux/dbs/wofs_ls_2023-03--P3M.db\"\n",
    "# Text file to get tasks ids from.\n",
    "tasks_text_file = \"s3://deafrica-waterbodies-dev/waterbodies/v0.0.2/senegal_basin/conflux/tasks/wofs_ls_2023-03--P3M_tasks.txt\"\n",
    "# Name of the plugin. Plugin file must be in the\n",
    "# deafrica_conflux/plugins/ directory.\n",
    "plugin_name = \"waterbodies_timeseries\"\n",
    "# Path to the directory containing the polygons raster files.\n",
    "polygons_rasters_directory = \"s3://deafrica-waterbodies-dev/waterbodies/v0.0.2/senegal_basin/conflux/historical_extent_rasters\"\n",
    "# JSON file containing the polygons ids.\n",
    "polygon_numericids_to_stringids_file = \"s3://deafrica-waterbodies-dev/waterbodies/v0.0.2/senegal_basin/conflux/historical_extent_rasters/polygon_numericids_to_stringids.json\"\n",
    "# Directory to write the drill outputs to.\n",
    "output_directory = \"s3://deafrica-waterbodies-dev/waterbodies/v0.0.2/senegal_basin/conflux/drill_output_parquet_files\"\n",
    "# Rerun tasks that have already been processed.\n",
    "overwrite = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ade937d-61b1-4ff6-b4de-ada9117b70b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logger.\n",
    "logging_setup(verbose)\n",
    "_log = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5f31dc-e687-4234-b985-2b609c27dc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support pathlib Paths\n",
    "cachedb_file_path = str(cachedb_file_path)\n",
    "tasks_text_file = str(tasks_text_file)\n",
    "polygons_rasters_directory = str(polygons_rasters_directory)\n",
    "output_directory = str(output_directory)\n",
    "if polygon_numericids_to_stringids_file:\n",
    "    polygon_numericids_to_stringids_file = str(polygon_numericids_to_stringids_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0e8e9a-2304-4a3d-aeeb-41c889e20ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the plugin as a Python module.\n",
    "module = import_module(f\"deafrica_conflux.plugins.{plugin_name}\")\n",
    "plugin_file = module.__file__\n",
    "plugin = run_plugin(plugin_file)\n",
    "_log.info(f\"Using plugin {plugin_file}\")\n",
    "validate_plugin(plugin)\n",
    "\n",
    "# Get the drill name from the plugin\n",
    "drill_name = plugin.product_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7494706-8d51-422a-aa9a-d0847352f44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if polygon_numericids_to_stringids_file:\n",
    "    if not check_file_exists(polygon_numericids_to_stringids_file):\n",
    "        _log.error(f\"File {polygon_numericids_to_stringids_file} does not exist!\")\n",
    "        raise FileNotFoundError(f\"File {polygon_numericids_to_stringids_file} does not exist!)\")\n",
    "\n",
    "if not check_dir_exists(polygons_rasters_directory):\n",
    "    _log.error(f\"Directory {polygons_rasters_directory} does not exist!\")\n",
    "    raise FileNotFoundError(f\"Directory {polygons_rasters_directory} does not exist!)\")\n",
    "\n",
    "# Create the output directory if it does not exist.\n",
    "if not check_dir_exists(output_directory):\n",
    "    if check_if_s3_uri(output_directory):\n",
    "        fsspec.filesystem(\"s3\").makedirs(output_directory, exist_ok=True)\n",
    "    else:\n",
    "        fsspec.filesystem(\"file\").makedirs(output_directory, exist_ok=True)\n",
    "    _log.info(f\"Created directory {output_directory}\")\n",
    "\n",
    "if not check_file_exists(cachedb_file_path):\n",
    "    _log.error(f\"Could not find the database file {cachedb_file_path}!\")\n",
    "    raise FileNotFoundError(f\"{cachedb_file_path} does not exist!\")\n",
    "else:\n",
    "    if check_if_s3_uri(cachedb_file_path):\n",
    "        cachedb_file_path = s3_download(cachedb_file_path)\n",
    "        if not check_file_exists(cachedb_file_path):\n",
    "            _log.error(f\"{cachedb_file_path} did not download!\")\n",
    "            raise FileNotFoundError(\n",
    "                f\"{cachedb_file_path} does not exist! File did not download.\"\n",
    "            )\n",
    "\n",
    "if not check_file_exists(tasks_text_file):\n",
    "    _log.error(f\"Could not find the text file {tasks_text_file}!\")\n",
    "    raise FileNotFoundError(f\"Could not find text file {tasks_text_file}!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d2a92a-a283-4712-9a45-d110c411b2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read task ids from the S3 URI or File URI.\n",
    "if check_if_s3_uri(tasks_text_file):\n",
    "    fs = fsspec.filesystem(\"s3\")\n",
    "else:\n",
    "    fs = fsspec.filesystem(\"file\")\n",
    "\n",
    "with fs.open(tasks_text_file, \"r\") as file:\n",
    "    tasks = [line.strip() for line in file]\n",
    "_log.info(f\"Read {len(tasks)} tasks from file.\")\n",
    "_log.debug(f\"Read {tasks} from file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecd82ec-9a79-4b07-af8e-181de133f2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the polygons ids mapping file.\n",
    "if polygon_numericids_to_stringids_file:\n",
    "    if check_if_s3_uri(polygon_numericids_to_stringids_file):\n",
    "        fs = fsspec.filesystem(\"s3\")\n",
    "    else:\n",
    "        fs = fsspec.filesystem(\"file\")\n",
    "\n",
    "    with fs.open(polygon_numericids_to_stringids_file) as f:\n",
    "        polygon_numericids_to_stringids = json.load(f)\n",
    "else:\n",
    "    polygon_numericids_to_stringids = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c682249c-b60d-4854-b52a-8e31c5f64710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the datacube\n",
    "dc = datacube.Datacube(app=\"deafrica-conflux-drill\")\n",
    "\n",
    "# Read the cache file\n",
    "cache = dscache.open_ro(cachedb_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba06f39-5f2f-4a8e-8b45-b1f9ac8fcd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_tasks = []\n",
    "for i, task in enumerate(tasks):\n",
    "    _log.info(f\"Processing task {task} ({i + 1}/{len(tasks)})\")\n",
    "\n",
    "    if not overwrite:\n",
    "        _log.info(f\"Checking existence of {task}\")\n",
    "        exists = table_exists(\n",
    "            drill_name=drill_name, task_id_string=task, output_directory=output_directory\n",
    "        )\n",
    "    if overwrite or not exists:\n",
    "        try:\n",
    "            # Perform the polygon drill.\n",
    "            table = drill(\n",
    "                plugin=plugin,\n",
    "                task_id_string=task,\n",
    "                cache=cache,\n",
    "                polygons_rasters_directory=polygons_rasters_directory,\n",
    "                polygon_numericids_to_stringids=polygon_numericids_to_stringids,\n",
    "                dc=dc,\n",
    "            )\n",
    "\n",
    "            pq_file_name = write_table_to_parquet(  # noqa F841\n",
    "                drill_name=drill_name,\n",
    "                task_id_string=task,\n",
    "                table=table,\n",
    "                output_directory=output_directory,\n",
    "            )\n",
    "        except KeyError as keyerr:\n",
    "            _log.exception(f\"Found task {task} has KeyError: {str(keyerr)}\")\n",
    "            failed_tasks = [].append(task)\n",
    "        except TypeError as typeerr:\n",
    "            _log.exception(f\"Found task {task} has TypeError: {str(typeerr)}\")\n",
    "            failed_tasks.append(task)\n",
    "        except RasterioIOError as ioerror:\n",
    "            _log.exception(f\"Found task {task} has RasterioIOError: {str(ioerror)}\")\n",
    "            failed_tasks.append(task)\n",
    "        except ValueError as valueerror:\n",
    "            _log.exception(f\"Found task {task} has ValueError: {str(valueerror)}\")\n",
    "            failed_tasks.append(task)\n",
    "        else:\n",
    "            _log.info(f\"Task {task} successful\")\n",
    "    else:\n",
    "        _log.info(f\"Drill outputs for {task} already exist, skipping\")\n",
    "\n",
    "    if failed_tasks:\n",
    "        # Write the failed dataset ids to a text file.\n",
    "        parent_folder, file_name = os.path.split(tasks_text_file)\n",
    "        file, file_extension = os.path.splitext(file_name)\n",
    "        failed_tasks_text_file = os.path.join(\n",
    "            parent_folder, file + \"_failed_tasks\" + file_extension\n",
    "        )\n",
    "\n",
    "        with fs.open(failed_tasks_text_file, \"a\") as file:\n",
    "            for task in failed_tasks:\n",
    "                file.write(f\"{task}\\n\")\n",
    "\n",
    "        _log.info(f\"Failed tasks {failed_tasks} written to: {failed_tasks_text_file}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
