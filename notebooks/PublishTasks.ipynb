{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ce5a81-8753-444c-a80e-4764160fd842",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# These are the default AWS configurations for the Analysis Sandbox.\n",
    "# that are set in the environmnet variables. \n",
    "aws_default_config = {\n",
    "    #'AWS_NO_SIGN_REQUEST': 'YES', \n",
    "    'AWS_SECRET_ACCESS_KEY': 'fake',\n",
    "    'AWS_ACCESS_KEY_ID': 'fake',\n",
    "}\n",
    "\n",
    "# To access public bucket, need to remove the AWS credentials in \n",
    "# the environment variables or the following error will occur.\n",
    "# PermissionError: The AWS Access Key Id you provided does not exist in our records.\n",
    "\n",
    "for key in aws_default_config.keys():\n",
    "    if key in os.environ:\n",
    "        del os.environ[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acab102-8c13-4147-9fa8-7cdc73a61e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "import boto3\n",
    "import click\n",
    "import fsspec\n",
    "from odc import dscache\n",
    "from odc.aws import s3_download\n",
    "from odc.stats._cli_common import parse_all_tasks\n",
    "\n",
    "#from deafrica_conflux.cli.common import MutuallyExclusiveOption\n",
    "from deafrica_conflux.cli.logs import logging_setup\n",
    "from deafrica_conflux.io import check_file_exists, check_if_s3_uri\n",
    "from deafrica_conflux.queues import get_queue_url, send_batch_with_retry\n",
    "from deafrica_conflux.text import task_id_to_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278c5663-748d-4ae0-b8b8-5c592a6d8f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = 1\n",
    "cachedb_file_path = \"s3://deafrica-waterbodies-dev/waterbodies/v0.0.2/senegal_basin/conflux/wofs_ls_2023-03--P3M.db\"\n",
    "tasks_sqs_queue = None\n",
    "tasks_text_file = \"s3://deafrica-waterbodies-dev/waterbodies/v0.0.2/senegal_basin/conflux/wofs_ls_2023-03--P3M_tasks.txt\"\n",
    "task_filter = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee9c6ac-4c7f-44a0-8b6e-6a07b8352ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logger.\n",
    "logging_setup(verbose)\n",
    "_log = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589bed97-1bea-4b02-ba49-1cc91ff61c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify\n",
    "if (tasks_sqs_queue and tasks_text_file) or (not tasks_sqs_queue and not tasks_text_file):\n",
    "    raise ValueError(\"Provide EITHER tasks_sqs_queue OR tasks_text_file!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0a6577-592d-49ce-a8c0-f23514b573ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support pathlib Paths.\n",
    "cachedb_file_path = str(cachedb_file_path)\n",
    "if tasks_text_file is not None:\n",
    "    tasks_text_file = str(tasks_text_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368b07f9-c5d2-4b4d-a642-522859a1b611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the cache db file exists.\n",
    "if not check_file_exists(cachedb_file_path):\n",
    "    raise FileNotFoundError(f\"{cachedb_file_path} does not exist!\")\n",
    "else:\n",
    "    if check_if_s3_uri(cachedb_file_path):\n",
    "        cachedb_file_path = s3_download(cachedb_file_path)\n",
    "        if not check_file_exists(cachedb_file_path):\n",
    "            raise FileNotFoundError(\n",
    "                f\"{cachedb_file_path} does not exist! File did not download.\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955977a7-8c9d-442a-b471-f9b8a4120d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the cache file\n",
    "cache = dscache.open_ro(cachedb_file_path)\n",
    "\n",
    "# Get all the tiles in the file db.\n",
    "cfg = cache.get_info_dict(\"stats/config\")\n",
    "grid = cfg[\"grid\"]\n",
    "\n",
    "all_tasks = sorted(idx for idx, _ in cache.tiles(grid)) if cache else []\n",
    "_log.info(f\"Found {len(all_tasks):,d} tasks in the file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31362e0-5380-4cbe-aaa0-f0d587e4c229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the tasks using the task filter.\n",
    "if len(task_filter) == 0:\n",
    "    tasks = all_tasks\n",
    "    _log.info(f\"Found {len(all_tasks):,d} tasks.\")\n",
    "else:\n",
    "    tasks = parse_all_tasks(task_filter, all_tasks)\n",
    "    _log.info(f\"Found {len(tasks):,d} tasks after filtering using filter {task_filter}\")\n",
    "\n",
    "tasks_str = [task_id_to_string(tidx) for tidx in tasks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036c78ec-480d-4553-b2ae-142d2794d9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if tasks_sqs_queue:\n",
    "    sqs_client = boto3.client(\"sqs\")\n",
    "    tasks_sqs_queue_url = get_queue_url(queue_name=tasks_sqs_queue, sqs_client=sqs_client)\n",
    "\n",
    "    # Check if there are any messages in the queue.\n",
    "    # If there are any messages purge the queue.\n",
    "    response = sqs_client.get_queue_attributes(\n",
    "        QueueUrl=tasks_sqs_queue_url, AttributeNames=[\"All\"]\n",
    "    )\n",
    "    if float(response[\"Attributes\"][\"ApproximateNumberOfMessages\"]) > 0:\n",
    "        _log.info(f\"Purging queue {tasks_sqs_queue_url}...\")\n",
    "        response = sqs_client.purge_queue(QueueUrl=tasks_sqs_queue_url)\n",
    "        time.sleep(60)  # Delay for 1 minute\n",
    "        _log.info(f\"Purge of queue {tasks_sqs_queue_url} is complete.\")\n",
    "\n",
    "    _, failed_to_push = send_batch_with_retry(\n",
    "        queue_url=tasks_sqs_queue_url, messages=tasks_str, max_retries=10, sqs_client=sqs_client\n",
    "    )\n",
    "    if failed_to_push:\n",
    "        _log.error(f\"Failed to push the tasks: {failed_to_push}\")\n",
    "elif tasks_text_file:\n",
    "    if check_if_s3_uri(tasks_text_file):\n",
    "        fs = fsspec.filesystem(\"s3\")\n",
    "    else:\n",
    "        fs = fsspec.filesystem(\"file\")\n",
    "    with fs.open(tasks_text_file, \"w\") as file:\n",
    "        for task in tasks_str:\n",
    "            file.write(f\"{task}\\n\")\n",
    "    _log.info(f\"{len(tasks_str)} tasks written to: {tasks_text_file}.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
