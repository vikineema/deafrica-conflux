{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3966324-a87b-4fc1-ab97-c83c357c4d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# These are the default AWS configurations for the Analysis Sandbox.\n",
    "# that are set in the environmnet variables. \n",
    "aws_default_config = {A\n",
    "    #'AWS_NO_SIGN_REQUEST': 'YES', \n",
    "    'AWS_SECRET_ACCESS_KEY': 'fake',\n",
    "    'AWS_ACCESS_KEY_ID': 'fake',\n",
    "}\n",
    "\n",
    "# To access public bucket, need to remove the AWS credentials in \n",
    "# the environment variables or the following error will occur.\n",
    "# PermissionError: The AWS Access Key Id you provided does not exist in our records.\n",
    "\n",
    "for key in aws_default_config.keys():\n",
    "    if key in os.environ:\n",
    "        del os.environ[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343f2e49-3166-4890-88d2-1c5c3ad6da39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import os\n",
    "import collections\n",
    "\n",
    "import click\n",
    "import fsspec\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import rasterio.features\n",
    "from datacube.utils.cog import to_cog\n",
    "from datacube.utils.dask import save_blob_to_file, save_blob_to_s3\n",
    "from datacube.utils.geometry import Geometry\n",
    "from odc.dscache.tools.tiling import parse_gridspec_with_name\n",
    "from odc.geo.geobox import GeoBox\n",
    "from odc.geo.xr import wrap_xr\n",
    "from pandas.api.types import is_float_dtype, is_integer_dtype, is_string_dtype\n",
    "\n",
    "from deafrica_conflux.cli.logs import logging_setup\n",
    "from deafrica_conflux.filter_polygons import get_intersecting_polygons\n",
    "from deafrica_conflux.id_field import guess_id_field\n",
    "from deafrica_conflux.io import check_dir_exists, check_file_exists, check_if_s3_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3b10eb-8a52-467a-af26-744a40e0ff09",
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = 0 #1\n",
    "# Grid name africa_{10|20|30|60}\n",
    "grid_name = \"africa_30\"\n",
    "# Datacube product to get tiles for from the grid.\n",
    "product = \"wofs_ls\"\n",
    "# Path to the polygons to be rasterised.\n",
    "# polygons_file_path = \"s3://deafrica-waterbodies-dev/waterbodies/v0.0.2/senegal_basin/historical_extent/waterbodies.parquet\"\n",
    "polygons_file_path = \"s3://deafrica-waterbodies-dev/waterbodies/v0.0.2/historical_extent/waterbodies.parquet\"\n",
    "# Unique key id in polygons vector file\n",
    "numeric_id = \"WB_ID\"\n",
    "string_id = \"UID\"\n",
    "# Directory to write the tiled polygon rasters to.\n",
    "output_directory = \"s3://deafrica-waterbodies-dev/waterbodies/v0.0.2/conflux/\"\n",
    "# Overwrite existing polygons raster file\n",
    "overwrite = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c567957f-3f52-4a24-ac47-cf5c08b29109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logger.\n",
    "logging_setup(verbose)\n",
    "_log = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1d44dd-05b8-4c9e-a474-1e1c8ea830a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support pathlib Paths.\n",
    "polygons_file_path = str(polygons_file_path)\n",
    "output_directory = str(output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541be28c-f21e-44ae-ad11-38b41cf75b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the output directory if it does not exist.\n",
    "is_s3 = check_if_s3_uri(output_directory)\n",
    "if is_s3:\n",
    "    fs = fsspec.filesystem(\"s3\")\n",
    "else:\n",
    "    fs = fsspec.filesystem(\"file\")\n",
    "\n",
    "if not check_dir_exists(output_directory):\n",
    "    fs.makedirs(output_directory, exist_ok=True)\n",
    "    _log.info(f\"Created directory {output_directory}\")\n",
    "\n",
    "tiles_output_directory = os.path.join(output_directory, \"product_tiles\")\n",
    "if not check_dir_exists(tiles_output_directory):\n",
    "    fs.makedirs(tiles_output_directory, exist_ok=True)\n",
    "    _log.info(f\"Created directory {tiles_output_directory}\")\n",
    "\n",
    "rasters_output_directory = os.path.join(output_directory, \"historical_extent_rasters\")\n",
    "if not check_dir_exists(rasters_output_directory):\n",
    "    fs.mkdirs(rasters_output_directory, exist_ok=True)\n",
    "    _log.info(f\"Created directory {output_directory}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f016aa45-1b96-4a3a-b9d6-462abcbdad19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the GridSpec.\n",
    "grid, gridspec = parse_gridspec_with_name(grid_name)\n",
    "_log.info(f\"Using the grid {grid} with {gridspec}\")\n",
    "\n",
    "# From the GridSpec get the crs and resolution.\n",
    "crs = gridspec.crs\n",
    "resolution = abs(gridspec.resolution[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb120968-7828-4f8a-8560-d5ab2b527ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the product footprint.\n",
    "product_footprint = gpd.read_file(\n",
    "    f\"https://explorer.digitalearth.africa/api/footprint/{product}\"\n",
    ").to_crs(crs)\n",
    "# Get the product footprint geopolygon.\n",
    "product_footprint = Geometry(geom=product_footprint.geometry[0], crs=crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756f9670-39ff-48cb-8398-7a2ce294eae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the tiles covering the product footprint.\n",
    "tiles = gridspec.tiles_from_geopolygon(geopolygon=product_footprint)\n",
    "tiles = list(tiles)\n",
    "\n",
    "# Get the individual tile geometries.\n",
    "tile_geometries = []\n",
    "tile_ids = []\n",
    "for tile in tiles:\n",
    "    tile_idx, tile_idy = tile[0]\n",
    "    tile_geometry = tile[1].extent.geom\n",
    "\n",
    "    tile_geometries.append(tile_geometry)\n",
    "    tile_ids.append(f\"x{tile_idx:03d}_y{tile_idy:03d}\")\n",
    "\n",
    "tiles_gdf = gpd.GeoDataFrame(data={\"tile_ids\": tile_ids, \"geometry\": tile_geometries}, crs=crs)\n",
    "_log.info(f\"Tile count: {len(tiles_gdf)}\")\n",
    "\n",
    "tiles_output_fp = os.path.join(tiles_output_directory, f\"{product}_tiles.parquet\")\n",
    "tiles_gdf.to_parquet(tiles_output_fp)\n",
    "_log.info(f\"{product} tiles written to {tiles_output_fp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9da693-1f2b-4824-b1b8-9a0de4b9f4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the polygons.\n",
    "try:\n",
    "    polygons_gdf = gpd.read_parquet(polygons_file_path).to_crs(crs)\n",
    "except Exception:\n",
    "    _log.info(\"Polygons vector file is not a parquet file\")\n",
    "    try:\n",
    "        polygons_gdf = gpd.read_file(polygons_file_path).to_crs(crs)\n",
    "    except Exception as error:\n",
    "        _log.error(f\"Could not load file {polygons_file_path}\")\n",
    "        _log.error(error)\n",
    "        raise error\n",
    "\n",
    "_log.info(f\"Polygon count {len(polygons_gdf)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbf98a8-a3a3-4eec-94a8-f925e79b441d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the id columns are unique.\n",
    "numeric_id = guess_id_field(input_gdf=polygons_gdf, use_id=numeric_id)\n",
    "assert is_integer_dtype(polygons_gdf[numeric_id]) or is_float_dtype(\n",
    "    polygons_gdf[numeric_id]\n",
    ")\n",
    "\n",
    "string_id = guess_id_field(input_gdf=polygons_gdf, use_id=string_id)\n",
    "assert is_string_dtype(polygons_gdf[string_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98406d1-bfa9-4300-8868-950bc44fcff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "polygon_numericids_to_stringids = dict(zip(polygons_gdf[numeric_id], polygons_gdf[string_id]))\n",
    "polygon_numericids_to_stringids_fp = os.path.join(rasters_output_directory, \"polygon_numericids_to_stringids.json\")\n",
    "with fs.open(polygon_numericids_to_stringids_fp, \"w\") as fp:\n",
    "    json.dump(polygon_numericids_to_stringids, fp)\n",
    "_log.info(f\"Polygon numeric IDs (WB_ID) to string IDs (UID) dictionary written to {polygon_numericids_to_stringids_fp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91dadde-d693-4d32-b7c7-925be836a67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_log.info(\"Filtering out tiles that do not intersect with any polygon...\")\n",
    "filtered_tiles_gdf = get_intersecting_polygons(\n",
    "    region=polygons_gdf, polygons_gdf=tiles_gdf, use_id=\"tile_ids\"\n",
    ")\n",
    "_log.info(f\"Filtered out {len(tiles_gdf) - len(filtered_tiles_gdf)} tiles.\")\n",
    "_log.info(f\"Filtered tiles count: {len(filtered_tiles_gdf)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4f97e4-bf5f-4984-bf2f-102c65e4759b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split each row in the tiles into a GeoDataFrame of its own.\n",
    "tiles = np.array_split(filtered_tiles_gdf, len(filtered_tiles_gdf))\n",
    "assert len(tiles) == len(filtered_tiles_gdf)\n",
    "\n",
    "polygons_stringids_to_tileids = collections.defaultdict(list)\n",
    "for i, tile in enumerate(tiles):\n",
    "    tile_id = tile[\"tile_ids\"].iloc[0]\n",
    "    tile_geometry = tile.geometry.iloc[0]\n",
    "    _log.info(f\"Rasterizing polygons for tile {tile_id} ({i + 1}/{len(tiles)})\")\n",
    "\n",
    "    tile_raster_fp = os.path.join(rasters_output_directory, f\"{tile_id}.tif\")\n",
    "\n",
    "    if not overwrite:\n",
    "        _log.info(f\"Checking existence of {tile_raster_fp}\")\n",
    "        exists = check_file_exists(tile_raster_fp)\n",
    "\n",
    "    if overwrite or not exists:\n",
    "        # Get the geobox for the region.\n",
    "        tile_geobox = GeoBox.from_geopolygon(\n",
    "            geopolygon=Geometry(geom=tile_geometry, crs=crs),\n",
    "            resolution=resolution,\n",
    "            crs=crs,\n",
    "        )\n",
    "\n",
    "        # Get the polygons that intersect with the tile.\n",
    "        tile_polygons = get_intersecting_polygons(\n",
    "            region=tile, polygons_gdf=polygons_gdf, use_id=numeric_id\n",
    "        )\n",
    "        for poly_id in tile_polygons[string_id].to_list():\n",
    "            polygons_stringids_to_tileids[poly_id].append(tile_id)\n",
    "        \"\"\"    \n",
    "        # Rasterise shapes into a numpy array\n",
    "        shapes = zip(tile_polygons.geometry, tile_polygons[numeric_id])\n",
    "        tile_raster_np = rasterio.features.rasterize(\n",
    "            shapes=shapes, out_shape=tile_geobox.shape, transform=tile_geobox.transform\n",
    "        )\n",
    "\n",
    "        # Convert numpy array to a full xarray.DataArray\n",
    "        tile_raster_ds = wrap_xr(im=tile_raster_np, gbox=tile_geobox)\n",
    "\n",
    "        # Write the raster to disk.\n",
    "        cog_bytes = to_cog(tile_raster_ds)\n",
    "        if check_if_s3_uri(tile_raster_fp):\n",
    "            save_blob_to_s3(data=cog_bytes, url=tile_raster_fp).compute()\n",
    "        else:\n",
    "            save_blob_to_file(data=cog_bytes, url=tile_raster_fp).compute()\n",
    "        _log.info(f\"Exported raster data to {tile_raster_fp}\")\n",
    "    else:\n",
    "        _log.info(f\"{tile_raster_fp} already exists, skipping...\")\n",
    "        \"\"\"                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c568a5-5bf6-4d85-be36-b6b16a747dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "polygons_stringids_to_tileids_fp = os.path.join(rasters_output_directory, \"polygons_stringids_to_tileids.json\")\n",
    "with fs.open(polygons_stringids_to_tileids_fp, \"w\") as fp:\n",
    "    json.dump(polygons_stringids_to_tileids, fp)\n",
    "_log.info(f\"Polygon string IDs (UID) to tile ids dictionary written to {polygons_stringids_to_tileids_fp}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
